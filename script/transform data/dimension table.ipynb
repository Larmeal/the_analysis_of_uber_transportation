{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"C:/Users/matur/OneDrive/Project/the_analysis_of_uber_transportation/script/cleaning data/transformed_uber_data.csv\")\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   passenger_count_id  7 non-null      int64\n",
      " 1   passenger_count     7 non-null      int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 244.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# Create passenger-count_dim table\n",
    "passenger_count = [0, 1, 2, 3, 4, 5, 6]\n",
    "passenger_count_id = [1, 2, 3, 4, 5, 6, 7]\n",
    "df_passenger = pd.DataFrame({'passenger_count_id': passenger_count_id, 'passenger_count': passenger_count})\n",
    "df_passenger.to_csv(\"passenger_count_dim.csv\", index=False)\n",
    "df_passenger.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   rate_code_id    6 non-null      int64 \n",
      " 1   ratecodeid      6 non-null      int64 \n",
      " 2   rate_code_name  6 non-null      string\n",
      "dtypes: int64(2), string(1)\n",
      "memory usage: 276.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# Create rate_code_dim table\n",
    "ratecodeid = [1, 2, 3, 4, 5, 6]\n",
    "rate_code_id = [1, 2, 3, 4, 5, 6]\n",
    "rate_code_name = ['Standard rate', 'JFK', 'Newark', 'Nassau or Westchester', 'Negotiated fare', 'Group ride']\n",
    "df_ratecode = pd.DataFrame({'rate_code_id' : rate_code_id, 'ratecodeid' : ratecodeid, 'rate_code_name' : rate_code_name})\n",
    "df_ratecode['rate_code_name'] = df_ratecode['rate_code_name'].astype('string')\n",
    "df_ratecode.to_csv(\"rate_code_dim.csv\", index=False)\n",
    "df_ratecode\n",
    "df_ratecode.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   payment_type_id    6 non-null      int64 \n",
      " 1   payment_type       6 non-null      int64 \n",
      " 2   payment_type_name  6 non-null      string\n",
      "dtypes: int64(2), string(1)\n",
      "memory usage: 276.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# Create payment_type_dim table\n",
    "payment_type = [1, 2, 3, 4, 5, 6]\n",
    "payment_type_id = [1, 2, 3, 4, 5, 6]\n",
    "payment_type_name = ['Credit card', 'Cash', 'No charge', 'Dispute', 'Unknown', 'Voided trip']\n",
    "df_payment_type = pd.DataFrame({'payment_type_id': payment_type_id, 'payment_type': payment_type, 'payment_type_name': payment_type_name})\n",
    "df_payment_type['payment_type_name'] = df_payment_type['payment_type_name'].astype('string')\n",
    "df_payment_type.to_csv(\"payment_type_dim.csv\", index = False)\n",
    "df_payment_type\n",
    "df_payment_type.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 97961 entries, 0 to 98912\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   pickup_location_id  97961 non-null  int64  \n",
      " 1   pickup_latitude     97961 non-null  float64\n",
      " 2   pickup_longitude    97961 non-null  float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Create pickup_location_dim table\n",
    "df_pickup_location = df[['pickup_latitude', 'pickup_longitude']]\n",
    "df_pickup_location = df_pickup_location.drop_duplicates()\n",
    "df_pickup_location['pickup_location_id'] = range(1, len(df_pickup_location) + 1)\n",
    "df_pickup_location = df_pickup_location.reindex(columns=['pickup_location_id', 'pickup_latitude', 'pickup_longitude'])\n",
    "df_pickup_location.to_csv('pickup_location_dim.csv', index=False)\n",
    "df_pickup_location\n",
    "df_pickup_location.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 98296 entries, 0 to 98912\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   dropoff_location_id  98296 non-null  int64  \n",
      " 1   dropoff_latitude     98296 non-null  float64\n",
      " 2   dropoff_longitude    98296 non-null  float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Create dropoff_location_dim table\n",
    "df_dropoff_location = df[['dropoff_latitude', 'dropoff_longitude']]\n",
    "df_dropoff_location = df_dropoff_location.drop_duplicates()\n",
    "df_dropoff_location['dropoff_location_id'] = range(1, len(df_dropoff_location) + 1)\n",
    "df_dropoff_location = df_dropoff_location.reindex(columns=['dropoff_location_id', 'dropoff_latitude', 'dropoff_longitude'])\n",
    "df_dropoff_location.to_csv('dropoff_location_dim.csv', index=False)\n",
    "df_dropoff_location\n",
    "df_dropoff_location.info()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26369 entries, 0 to 98909\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   datetime_id            26369 non-null  int64         \n",
      " 1   tpep_pickup_datetime   26369 non-null  datetime64[ns]\n",
      " 2   pick_hour              26369 non-null  int64         \n",
      " 3   pick_day               26369 non-null  int64         \n",
      " 4   pick_month             26369 non-null  int64         \n",
      " 5   pick_year              26369 non-null  int64         \n",
      " 6   pick_weekday           26369 non-null  int64         \n",
      " 7   tpep_dropoff_datetime  26369 non-null  datetime64[ns]\n",
      " 8   drop_hour              26369 non-null  int64         \n",
      " 9   drop_day               26369 non-null  int64         \n",
      " 10  drop_month             26369 non-null  int64         \n",
      " 11  drop_year              26369 non-null  int64         \n",
      " 12  drop_weekday           26369 non-null  int64         \n",
      "dtypes: datetime64[ns](2), int64(11)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Create datetime_dim table\n",
    "\n",
    "# Convert data type: object to datetime \n",
    "columns_to_convert_datetime = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"]\n",
    "df[columns_to_convert_datetime] = df[columns_to_convert_datetime].apply(pd.to_datetime)\n",
    "\n",
    "# Create df_datetime dataframe\n",
    "df_datetime = df[['tpep_pickup_datetime','tpep_dropoff_datetime']]\n",
    "df_datetime = df_datetime.drop_duplicates()\n",
    "\n",
    "# Change format datetime\n",
    "df_datetime['tpep_pickup_datetime'] = df_datetime['tpep_pickup_datetime'].dt.strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "df_datetime['tpep_dropoff_datetime'] = df_datetime['tpep_dropoff_datetime'].dt.strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "# Create datetime_id column\n",
    "df_datetime['datetime_id'] = range(1, len(df_datetime) + 1)\n",
    "\n",
    "# Extract hour, day, month, year, weekday from timestamp\n",
    "df_datetime['pick_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "df_datetime['pick_day'] = df['tpep_pickup_datetime'].dt.day\n",
    "df_datetime['pick_month'] = df['tpep_pickup_datetime'].dt.month\n",
    "df_datetime['pick_year'] = df['tpep_pickup_datetime'].dt.year\n",
    "df_datetime['pick_weekday'] = df['tpep_pickup_datetime'].dt.dayofweek +1\n",
    "\n",
    "\n",
    "df_datetime['drop_hour'] = df['tpep_dropoff_datetime'].dt.hour\n",
    "df_datetime['drop_day'] = df['tpep_dropoff_datetime'].dt.day\n",
    "df_datetime['drop_month'] = df['tpep_dropoff_datetime'].dt.month\n",
    "df_datetime['drop_year'] = df['tpep_dropoff_datetime'].dt.year\n",
    "df_datetime['drop_weekday'] = df['tpep_dropoff_datetime'].dt.dayofweek +1 \n",
    "\n",
    "\n",
    "# Reundex column\n",
    "df_datetime = df_datetime.reindex(columns=['datetime_id', 'tpep_pickup_datetime', 'pick_hour', 'pick_day', 'pick_month', 'pick_year', 'pick_weekday', 'tpep_dropoff_datetime', 'drop_hour', 'drop_day', 'drop_month', 'drop_year', 'drop_weekday'])\n",
    "\n",
    "# Export to csv dile\n",
    "df_datetime.to_csv('datetime_dim.csv', index=False)\n",
    "\n",
    "# Convert object to datetime \n",
    "convert_datetime = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"]\n",
    "df_datetime[convert_datetime] = df_datetime[convert_datetime].apply(pd.to_datetime)\n",
    "\n",
    "df_datetime\n",
    "df_datetime.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 98913 entries, 0 to 98912\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   trip_id                98913 non-null  int64  \n",
      " 1   vendor_id              98913 non-null  int64  \n",
      " 2   datetime_id            98913 non-null  int64  \n",
      " 3   passenger_count_id     98913 non-null  int64  \n",
      " 4   rate_code_id           98913 non-null  int64  \n",
      " 5   store_and_fwd_flag     98913 non-null  string \n",
      " 6   pickup_location_id     98913 non-null  int64  \n",
      " 7   dropoff_location_id    98913 non-null  int64  \n",
      " 8   payment_type_id        98913 non-null  int64  \n",
      " 9   trip_distance_id       98913 non-null  int64  \n",
      " 10  fare_amount            98913 non-null  float64\n",
      " 11  extra                  98913 non-null  float64\n",
      " 12  mta_tax                98913 non-null  float64\n",
      " 13  tip_amount             98913 non-null  float64\n",
      " 14  tolls_amount           98913 non-null  float64\n",
      " 15  improvement_surcharge  98913 non-null  float64\n",
      " 16  total_amount           98913 non-null  float64\n",
      "dtypes: float64(7), int64(9), string(1)\n",
      "memory usage: 13.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Merge datetime_id column in fact_table\n",
    "merge_data = pd.merge(df, df_datetime[['datetime_id','tpep_pickup_datetime', 'tpep_dropoff_datetime']], on=['tpep_pickup_datetime', 'tpep_dropoff_datetime'], how='left')\n",
    "merge_data['datetime_id_new'] = merge_data['datetime_id']\n",
    "merge_data.drop(['datetime_id','tpep_pickup_datetime', 'tpep_dropoff_datetime'], axis=1, inplace=True)\n",
    "merge_data = merge_data.rename(columns={'datetime_id_new': 'datetime_id'})\n",
    "\n",
    "# Merge passenger_count_id column in fact_table\n",
    "merge_data = pd.merge(merge_data, df_passenger[['passenger_count_id', 'passenger_count']], on=['passenger_count'], how='left')\n",
    "merge_data['passenger_count_id_new'] = merge_data['passenger_count_id']\n",
    "merge_data.drop(['passenger_count_id', 'passenger_count'], axis=1, inplace=True)\n",
    "merge_data = merge_data.rename(columns={'passenger_count_id_new': 'passenger_count_id'})\n",
    "\n",
    "# Merge rate_code_id column in fact_table\n",
    "merge_data = pd.merge(merge_data, df_ratecode[['rate_code_id', 'ratecodeid']], on=['ratecodeid'], how='left')\n",
    "merge_data['rate_code_id_new'] = merge_data['rate_code_id']\n",
    "merge_data.drop(['rate_code_id','ratecodeid'], axis=1, inplace=True)\n",
    "merge_data = merge_data.rename(columns={'rate_code_id_new': 'rate_code_id'})\n",
    "\n",
    "# Merge pickup_location_id column in fact_table\n",
    "merge_data = pd.merge(merge_data, df_pickup_location[['pickup_location_id','pickup_latitude', 'pickup_longitude']], on=['pickup_latitude', 'pickup_longitude'], how='left')\n",
    "merge_data['pickup_location_id_new'] = merge_data['pickup_location_id']\n",
    "merge_data.drop(['pickup_location_id','pickup_latitude', 'pickup_longitude'], axis=1, inplace=True)\n",
    "merge_data = merge_data.rename(columns={'pickup_location_id_new': 'pickup_location_id'})\n",
    "\n",
    "# Merge dropoff_location_id column in fact_table\n",
    "merge_data = pd.merge(merge_data, df_dropoff_location[['dropoff_location_id','dropoff_latitude', 'dropoff_longitude']], on=['dropoff_latitude', 'dropoff_longitude'], how='left')\n",
    "merge_data['dropoff_location_id_new'] = merge_data['dropoff_location_id']\n",
    "merge_data.drop(['dropoff_location_id','dropoff_latitude', 'dropoff_longitude'], axis=1, inplace=True)\n",
    "merge_data = merge_data.rename(columns={'dropoff_location_id_new': 'dropoff_location_id'})\n",
    "\n",
    "# Merge payment_type_id column in fact_table\n",
    "merge_data = pd.merge(merge_data, df_payment_type[['payment_type_id', 'payment_type']], on=['payment_type'], how='left')\n",
    "merge_data['payment_type_id_new'] = merge_data['payment_type_id']\n",
    "merge_data.drop(['payment_type_id', 'payment_type'], axis=1, inplace=True)\n",
    "merge_data = merge_data.rename(columns={'payment_type_id_new': 'payment_type_id'})\n",
    "\n",
    "# Add trip_id in fact_table\n",
    "merge_data['trip_id'] = range(1, len(merge_data) + 1)\n",
    "\n",
    "\n",
    "# Change data type\n",
    "merge_data['store_and_fwd_flag']  = merge_data['store_and_fwd_flag'].astype('string')\n",
    "merge_data['trip_distance'] = merge_data['trip_distance'].astype('int64')\n",
    "\n",
    "# Rename some column\n",
    "merge_data = merge_data.rename(columns={'vendorid': 'vendor_id', 'trip_distance': 'trip_distance_id'})\n",
    "\n",
    "# Reindex data\n",
    "merge_data = merge_data.reindex(columns=['trip_id', 'vendor_id', 'datetime_id', 'passenger_count_id', 'rate_code_id', 'store_and_fwd_flag', 'pickup_location_id', 'dropoff_location_id', 'payment_type_id', 'trip_distance_id', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount'])\n",
    "merge_data.to_csv('fact_table.csv', index='False')\n",
    "\n",
    "merge_data\n",
    "merge_data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
